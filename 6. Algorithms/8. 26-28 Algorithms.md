## 26. Bellman-Ford Algorithm

Bellman-Ford is an algorithm that finds the shortest path from a single source node to all other nodes in a weighted graph. Its key advantage over Dijkstra's is its ability to handle graphs with **negative edge weights**.

### The Core Idea

The algorithm is beautifully simple: it repeatedly "relaxes" every single edge in the graph. Relaxing an edge `(u, v)` with weight `w` means checking if the path from the source to `v` can be shortened by going through `u` first.

1. **Initialization:** Set the distance to the source node as `0` and all other distances to infinity.
2. **Relaxation Loop:** Repeat `V-1` times (where `V` is the number of vertices):
    - For every edge `(u, v)` with weight `w` in the graph:
        - If `distance[u] + w < distance[v]`, then update `distance[v] = distance[u] + w`.
3. **Negative Cycle Check (Optional):** After the main loop, do one more pass over all edges. If any distance can still be improved, it means the graph contains a negative-weight cycle that is reachable from the source.

Why `V-1` times? Because the longest possible simple path (without cycles) in a graph can have at most `V-1` edges.

### Visual Diagram & Trace

**Goal:** Find shortest paths from **A**.

```
      (6)
    A-----B
    | \   | (5)
(-4)|  \  |
    | (5)\ |
    C-----D----E
      (3)  (-2)
```

**`dist` array:** `[A:0, B:inf, C:inf, D:inf, E:inf]`

- **Iteration 1:**
    
    - `A->B`: `dist[B]` becomes `6`.
    - `A->C`: `dist[C]` becomes `-4`.
    - `A->D`: `dist[D]` becomes `5`.
    - `C->D`: `dist[D]` was `5`, now `-4+3=-1`. It becomes `-1`.
    - ... (other edges don't improve anything yet)
    - **End of Iteration 1:** `dist = [A:0, B:6, C:-4, D:-1, E:inf]`
    
- **Iteration 2:**
    
    - `B->D`: `dist[D]` was `-1`, now `6+5=11`. No change.
    - `D->E`: `dist[E]` was `inf`, now `-1 + (-2) = -3`. It becomes `-3`.
    - ... (other edges don't cause improvements)
    - **End of Iteration 2:** `dist = [A:0, B:6, C:-4, D:-1, E:-3]`
    
- **Iterations 3 & 4:** No further changes occur. The algorithm stabilizes.

**Final Distances from A:** `{A:0, B:6, C:-4, D:-1, E:-3}`

### Complexities

- **Time Complexity:** O(VtimesE) because the main loop runs `V-1` times, and inside it, we iterate through all `E` edges.
- **Space Complexity:** O(V) to store the distances array.

### Core LeetCode Problem & Solution

While Bellman-Ford can detect negative cycles, its structure is also perfect for problems with a limited number of "steps".

- **Problem:** [787. Cheapest Flights Within K Stops](https://leetcode.com/problems/cheapest-flights-within-k-stops/)
- **Description:** Find the cheapest flight from `src` to `dst` with at most `k` stops.

#### Python Code Solution

Python

```python
def findCheapestPrice(n: int, flights: list[list[int]], src: int, dst: int, k: int) -> int:
    # Initialize distances to infinity, source to 0
    prices = [float('inf')] * n
    prices[src] = 0

    # The loop runs k+1 times (for k stops, we can have k+1 edges)
    for i in range(k + 1):
        # Create a temporary copy to ensure updates from one iteration
        # don't affect calculations within the same iteration.
        temp_prices = prices.copy()
        
        for s, d, p in flights: # source, destination, price
            if prices[s] == float('inf'):
                continue
            if prices[s] + p < temp_prices[d]:
                temp_prices[d] = prices[s] + p
        
        prices = temp_prices
        
    return prices[dst] if prices[dst] != float('inf') else -1
```

### LeetCode Variants

1. **Negative Cycle Detection:** This is the classic use case. After running the main `V-1` loops, run one more. If any `distance[v]` can be updated, a negative cycle exists. This is crucial in applications like arbitrage detection in currency exchange.

---
## 27. Floyd-Warshall Algorithm

Floyd-Warshall is a dynamic programming algorithm used to find the shortest paths between **all pairs** of vertices in a weighted graph (the All-Pairs Shortest Path problem). It can handle positive or negative edge weights but will not work correctly if there are negative cycles.

### The Core Idea

The algorithm works by incrementally allowing more and more vertices to be used as "intermediate" nodes in a path. It asks a simple question over and over: "Is the path from node `i` to node `j` shorter if we are allowed to go through node `k`?"

1. **Initialization:** Create a `V x V` distance matrix. `dist[i][j]` is the weight of the direct edge from `i` to `j`, or `infinity` if there is no direct edge. `dist[i][i]` is `0`.
2. **Main Loop:** Use three nested loops (`k`, `i`, `j`):
    - For every possible intermediate vertex `k`:
        - For every possible source vertex `i`:
            - For every possible destination vertex `j`:
                - `dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])`
                    

After the loops complete, the matrix will contain the shortest path distances between every pair of nodes.

### Visual Diagram & Trace

**Graph:**

```
      (3)
    1-----2
    | \   | (1)
 (8)|  \  |
    | (-4)\ |
    4-----3
      (2)
```

**Initial Distance Matrix:**

```
  1    2    3    4
1[0,   3,  inf,  8]
2[inf, 0,   1,  inf]
3[inf,inf,  0,   -4]
4[inf,inf,  2,   0]
```

**Let's allow `k=1` as an intermediate node.** Nothing changes, as `1` is a source.

**Let's allow `k=2` as an intermediate node.**

- Path `1 -> 3`: Current is `inf`. Is `1->2->3` better? `dist[1][2] + dist[2][3] = 3 + 1 = 4`. Yes. `dist[1][3]` becomes `4`.
    

**Let's allow `k=3` as an intermediate node.**

- Path `1 -> 4`: Current is `8`. Is `1->3->4` better? `dist[1][3] + dist[3][4] = 4 + (-4) = 0`. Yes. `dist[1][4]` becomes `0`.
    
- Path `2 -> 4`: Current is `inf`. Is `2->3->4` better? `dist[2][3] + dist[3][4] = 1 + (-4) = -3`. Yes. `dist[2][4]` becomes `-3`.
    

...and so on, until all nodes have been considered as intermediate points.

### Complexities

- **Time Complexity:** O(V3) due to the three nested loops.
- **Space Complexity:** O(V2) to store the distance matrix.

### Core LeetCode Problem & Solution

- **Problem:** [1334. Find the City With the Smallest Number of Neighbors at a Threshold Distance](https://leetcode.com/problems/find-the-city-with-the-smallest-number-of-neighbors-at-a-threshold-distance/)
- **Description:** Given cities and weighted roads, find the city that can reach the fewest other cities within a given `distanceThreshold`.

#### Python Code Solution

Python

```python
def findTheCity(n: int, edges: list[list[int]], distanceThreshold: int) -> int:
    # 1. Initialize distance matrix
    dist = [[float('inf')] * n for _ in range(n)]
    for i in range(n):
        dist[i][i] = 0
    for u, v, w in edges:
        dist[u][v] = w
        dist[v][u] = w

    # 2. Floyd-Warshall algorithm
    for k in range(n):
        for i in range(n):
            for j in range(n):
                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])

    # 3. Find the result city
    min_reachable_count = n
    result_city = -1
    for i in range(n):
        reachable_count = 0
        for j in range(n):
            if i != j and dist[i][j] <= distanceThreshold:
                reachable_count += 1
        
        if reachable_count <= min_reachable_count:
            min_reachable_count = reachable_count
            result_city = i
            
    return result_city
```

### LeetCode Variants

1. **Transitive Closure of a Graph:** Floyd-Warshall can be adapted to find if a path exists between all pairs. Initialize with `1` for edges and `0` for self-loops. The update rule becomes `dist[i][j] = dist[i][j] OR (dist[i][k] AND dist[k][j])`.

---

## 28. Backtracking

Backtracking is a general algorithmic technique for finding all (or some) solutions to a computational problem, notably constraint satisfaction problems. It incrementally builds candidates for the solutions and abandons a candidate ("backtracks") as soon as it determines that the candidate cannot possibly be completed to a valid solution.

### The Core Idea

It's a refined, systematic, depth-first search of the solution space.

1. **Choose:** Start with a choice.
2. **Explore:** Recursively explore the consequences of that choice.
3. **Unchoose (Backtrack):** If the exploration leads to a dead end or an invalid solution, undo the original choice and try the next available option.

This "choose, explore, unchoose" pattern is the heart of every backtracking algorithm.

### Visual Diagram & Trace (Finding Permutations of `[1, 2]`)

```
                      (start)
                      /      \
Choose 1            /        \            Choose 2
                [1]            [2]
                /              \
Choose 2      /                \          Choose 1
            [1, 2]             [2, 1]
            (solution)         (solution)
            /                  \
Unchoose 2  /                    \          Unchoose 1
          [1]                      [2]
          /                        \
Unchoose 1/                          \        Unchoose 2
        []                           []
        (done)                       (done)
```

### Complexities

- **Time Complexity:** Highly variable. It depends on the number of possible solutions and how much pruning can be done. It's often exponential, e.g., O(N) for permutations, O(2N) for subsets.
- **Space Complexity:** Depends on the recursion depth, often O(N).

### Core LeetCode Problem & Solution

- **Problem:** [46. Permutations](https://leetcode.com/problems/permutations/)
- **Description:** Given an array `nums` of distinct integers, return all possible permutations.

#### Python Code Solution

Python

```python
def permute(nums: list[int]) -> list[list[int]]:
    result = []
    
    def backtrack(start_index):
        # Base case: if we've reached the end, we have a full permutation.
        if start_index == len(nums):
            result.append(nums[:]) # Append a copy of the current state
            return

        for i in range(start_index, len(nums)):
            # 1. Choose: Swap the current element with the start_index element.
            nums[start_index], nums[i] = nums[i], nums[start_index]
            
            # 2. Explore: Recurse for the rest of the array.
            backtrack(start_index + 1)
            
            # 3. Unchoose (Backtrack): Swap them back to restore the original state
            # for the next iteration of the loop.
            nums[start_index], nums[i] = nums[i], nums[start_index]

    backtrack(0)
    return result
```

### LeetCode Variants

1. **[78. Subsets](https://leetcode.com/problems/subsets/)**
    
    - **Variation:** Find all possible subsets (the power set).
    - **Logic Change:** The decision for each element is binary: either include it in the current subset or don't.
    - **Brief Explanation:** A common pattern is `backtrack(start_index, current_subset)`. In the recursive call, you first add `current_subset` to the results. Then you loop from `start_index` to the end. In the loop, you "choose" `nums[i]`, recurse with `i+1`, and then "unchoose" `nums[i]` by popping it from `current_subset`.
        
2. **[39. Combination Sum](https://leetcode.com/problems/combination-sum/)**
    
    - **Variation:** Find all unique combinations that sum up to a target. Numbers can be reused.
    - **Logic Change:** The recursion needs to handle the target sum. When you "choose" a number, you subtract it from the target. The base cases are when the target is `0` (a solution) or less than `0` (a dead end).
    - **Brief Explanation:** `backtrack(remaining_target, current_combo, start_index)`. The key change is that in the recursive call, you pass `i` instead of `i+1` to allow the same number to be reused: `backtrack(new_target, combo, i)`.
        
3. **[51. N-Queens](https://leetcode.com/problems/n-queens/)**
    
    - **Variation:** Place N queens on an N x N chessboard so that no two queens threaten each other.
    - **Logic Change:** This is a classic constraint satisfaction problem. The "choice" is placing a queen in a specific square. The "constraint" is checking if that square is under attack from other queens already placed.
    - **Brief Explanation:** `backtrack(row)`. Loop through columns `col` for the current `row`. If `(row, col)` is a safe square, place a queen there. Then recurse: `backtrack(row + 1)`. After the recursive call returns, "unchoose" by removing the queen to explore other possibilities.
---
